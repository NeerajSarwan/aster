"""

Maggle : a kaggle bot to create baseline models for different category of kaggle competitions or datasets

__author__ == "shivam bansal"
__email__ == "shivam5992@gmail.com"

"""


""" make necessary imports """

import nbformat 



class maggle():
	def __init__(self, config):

		# initialize important variables
		self.nb = nbformat.v4.new_notebook()
		self.nb['cells'] = []

		## add the intro text cell
		text = """	## Baseline Model Pipeline : Titanic Machine Learning from Disaster 

					This is the baseline kernel (automatically generated by Bot: AIsha). In this kernel, an end to end classification pipeline is implemented.

					### Contents 

					1. Prepare Environment  
					2. Dataset Preparation  
					3. Data Preprocessing   
					4. Modelling   
					&nbsp;&nbsp;&nbsp;&nbsp; 4.1 Logistic Regression  
					&nbsp;&nbsp;&nbsp;&nbsp; 4.2 Random Forest  
					&nbsp;&nbsp;&nbsp;&nbsp; 4.3 Extereme Gradient Boosting  
					5. Feature Importance   
					6. Creating Submission  """

		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		self.config = config

	def _prepare_environment(self):

		## add the intro text cell
		text = """	## Step 1: Prepare Environment
					Lets load the required libraries to be used"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## add the code cell
		code = """	from sklearn.model_selection import train_test_split
					from sklearn.ensemble import RandomForestClassifier
					from sklearn.linear_model import LogisticRegression
					from sklearn.preprocessing import LabelEncoder
					from xgboost import plot_importance
					import matplotlib.pyplot as plt
					import xgboost as xgb 
					import pandas as pd"""
		code = code.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

	def _dataset_preparation(self):

		## add the intro text cell
		text = """	## Step 2: Dataset Preparation
					Load the train and test dataset into memory"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## add the code cell
		code = """	## read dataset
					train_df = pd.read_csv('../input/train.csv')
					test_df = pd.read_csv("../input/test.csv")

					## get predictor and target variables
					_target = "Survived"
					_id = "PassengerId" 
					Y = train_df[_target]
					test_id = test_df[_id]

					## drop the target and id columns
					train_df = train_df.drop([_target, _id], axis=1)
					test_df = test_df.drop([_id], axis=1)"""

		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

		## add the intro text cell
		text = """	Lets look at the dataset snapshot and summary"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		code = """	## snapshot of train and test
					train_df.head()"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

		code = """	## summary of train and test
					train_df.describe()"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

	def _dataset_preprocessing(self):
		## add the intro text cell
		text = """	## Step 3: Data Preprocessing

					In the data preprocessing step, we will perform label encoding of categorical variables and handle missing values.

					### 3.1 Label Encoding
					In this step, convert the categorical variables into label encoded forms """
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	## label encoding of categorical variables 
					columns = train_df.columns
					num_cols = train_df._get_numeric_data().columns
					cat_cols = list(set(columns) - set(num_cols))
					    
					for col in cat_cols: 
					    le = LabelEncoder()
					    le.fit(list(train_df[col].values) + list(test_df[col].values))
					    train_df[col] = le.transform(list(train_df[col].values))
					    test_df[col] = le.transform(list(test_df[col].values))"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


		## add the intro text cell
		text = """	### 3.2 Missing Values Treatment

					Handle the missing values, for continuous variables, replace by mean. For categorical variables, replace by mode"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	## for numerical columns, replace the missing values by mean
					train_df[num_cols] = train_df[num_cols].fillna(train_df[num_cols].mean())
					test_df[num_cols] = test_df[num_cols].fillna(test_df[num_cols].mean())

					## for categorical columns, replace the missing values by mode
					train_df[cat_cols] = train_df[cat_cols].fillna(train_df[cat_cols].mode())
					test_df[cat_cols] = test_df[cat_cols].fillna(test_df[cat_cols].mode())"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


	def _baseline_model(self):
		## add the intro text cell
		text = """	## Step 4 : Create baseline model

					Next step is the modelling step, lets start with the simple linear model 

					### 4.1 : Logistic Regression

					Train a binary classifier logistic regression"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	model = LogisticRegression()
					model.fit(train_df, Y)
					pred = model.predict(test_df)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


		## add the intro text cell
		text = """	### 4.2 : Random Forest Classifier

					Now, lets train a tree based model : random forest"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	model = RandomForestClassifier()
					model.fit(train_df, Y)
					pred = model.predict(test_df)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

		## add the intro text cell
		text = """	### 4.3 : xgBoost Classifier

					Lets train the extereme gradient boosting : xgboost classifier"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	model = xgb.XGBClassifier(n_estimators=300, learning_rate=0.01)
					model.fit(train_df, Y)
					pred = model.predict(test_df)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

	def _feature_importance(self):
		## add the intro text cell
		text = """	## Step 5: Feature Importance

					Lets look at some of the important features"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	plt.figure(figsize=(20,16));
					plot_importance(model, );"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


	def _submission(self):
		## add the intro text cell
		text = """	## Step 6 : Create Submission File

					Finally, create the submission file from the extereme graident boosting model"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))


		# self.submission_doc[_target] = pred
		code = """	sub = pd.DataFrame()
					sub[_id] = test_id
					sub[_target] = pred
					sub.to_csv("baseline_submission.csv", index=False)
					sub.head(10)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


	def _generate_notebook(self):
		self._prepare_environment()
		self._dataset_preparation()
		self._dataset_preprocessing()
		self._baseline_model()
		self._feature_importance()
		self._submission()
		nbformat.write(self.nb, 'baseline.ipynb')

if __name__ == "__main__":
	config = {  }
	mg = maggle(config)
	mg._generate_notebook()


