"""

Maggle : a kaggle bot to create baseline models for different category of kaggle competitions or datasets

__author__ == "shivam bansal"
__email__ == "shivam5992@gmail.com"

"""


""" make necessary imports """

import nbformat 



class maggle():
	def __init__(self, config):

		# initialize important variables
		self.nb = nbformat.v4.new_notebook()
		self.nb['cells'] = []

		## add the intro text cell
		text = """	## Baseline Model Pipeline   

					This is the baseline kernel (automatically generated by my bot: Maggle). In this kernel, an end to end classification pipeline is implemented.

					### Contents 

					1. Prepare Environment  
					2. Preparation and Exploration   
					&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Dataset Snapshot and Summary    
					&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Target Variable Distribution    
					&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Missing Values    
					&nbsp;&nbsp;&nbsp;&nbsp; 2.4 Variable Correlations
					3. Preprocessing  
					&nbsp;&nbsp;&nbsp;&nbsp; 3.1 Label Encoding    
					&nbsp;&nbsp;&nbsp;&nbsp; 3.2 Missing Values Treatment     
					&nbsp;&nbsp;&nbsp;&nbsp; 3.3 Feature Engineering   
					&nbsp;&nbsp;&nbsp;&nbsp; 3.4 Train Test Split    
					4. Modelling   
					&nbsp;&nbsp;&nbsp;&nbsp; 4.1 Logistic Regression  
					&nbsp;&nbsp;&nbsp;&nbsp; 4.2 Random Forest  
					&nbsp;&nbsp;&nbsp;&nbsp; 4.3 Extereme Gradient Boosting  
					5. Feature Importance   
					6. Creating Submission  """

		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))
		self.config = config

	def _prepare_environment(self):

		## add the intro text cell
		text = """	## Step 1: Prepare Environment
					Lets load the required libraries to be used"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## add the code cell
		code = """	from sklearn.feature_extraction.text import TfidfVectorizer
					from sklearn.model_selection import train_test_split
					from sklearn.ensemble import RandomForestClassifier
					from sklearn.linear_model import LogisticRegression
					from sklearn.preprocessing import LabelEncoder
					from sklearn.metrics import confusion_matrix
					from sklearn.model_selection import KFold
					from sklearn.metrics import roc_auc_score
					from sklearn.metrics import roc_curve
					from xgboost import plot_importance
					from collections import Counter
					import matplotlib.pyplot as plt
					from sklearn import metrics
					import seaborn as sns 
					import xgboost as xgb 
					import pandas as pd
					import numpy as np 
					import itertools"""
		self.nb['cells'].append(nbformat.v4.new_code_cell(code).replace("\t",""))

	def _dataset_preparation(self):

		## add the intro text cell
		text = """	## Step 2: Dataset Preparation
					Load the train and test dataset into memory"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## add the code cell
		code = """	## read dataset
					train_df = pd.read_csv('../input/train 2.csv')
					test_df = pd.read_csv("../input/test 2.csv")

					## get predictor and target variables
					_target = "Survived"
					_id = "PassengerId" 

					_target = "author"
					_id = "id" 
					tag = "text"

					Y = train_df[_target]
					distinct_Y = Y.value_counts().index
					test_id = test_df[_id]

					## drop the target and id columns
					train_df = train_df.drop([_target, _id], axis=1)
					test_df = test_df.drop([_id], axis=1)

					textcol = 'text'"""

		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

		## add the intro text cell
		text = """	### 2.1 Dataset snapshot and summary"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		code = """	## snapshot of train and test
					train_df.head()"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

		code = """	## summary of train and test
					train_df.describe()"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

	def _dataset_preprocessing(self):
		## add the intro text cell
		text = """	## Step 3: Data Preprocessing

					In the data preprocessing step, we will perform label encoding of categorical variables and handle missing values.

					### 3.1 Label Encoding
					In this step, convert the categorical variables into label encoded forms """
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	## label encoding of categorical variables 
					columns = train_df.columns
					num_cols = train_df._get_numeric_data().columns
					cat_cols = list(set(columns) - set(num_cols))
					    
					for col in cat_cols: 
					    le = LabelEncoder()
					    le.fit(list(train_df[col].values) + list(test_df[col].values))
					    train_df[col] = le.transform(list(train_df[col].values))
					    test_df[col] = le.transform(list(test_df[col].values))"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


		## add the intro text cell
		text = """	### 3.2 Missing Values Treatment

					Handle the missing values, for continuous variables, replace by mean. For categorical variables, replace by mode"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	## for numerical columns, replace the missing values by mean
					train_df[num_cols] = train_df[num_cols].fillna(train_df[num_cols].mean())
					test_df[num_cols] = test_df[num_cols].fillna(test_df[num_cols].mean())

					## for categorical columns, replace the missing values by mode
					train_df[cat_cols] = train_df[cat_cols].fillna(train_df[cat_cols].mode())
					test_df[cat_cols] = test_df[cat_cols].fillna(test_df[cat_cols].mode())"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


	def _baseline_model(self):
		## add the intro text cell
		text = """	## Step 4 : Create baseline model

					Next step is the modelling step, lets start with the simple linear model 

					### 4.1 : Logistic Regression

					Train a binary classifier logistic regression"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	model = LogisticRegression()
					model.fit(train_df, Y)
					pred = model.predict(test_df)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


		## add the intro text cell
		text = """	### 4.2 : Random Forest Classifier

					Now, lets train a tree based model : random forest"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	model = RandomForestClassifier()
					model.fit(train_df, Y)
					pred = model.predict(test_df)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

		## add the intro text cell
		text = """	### 4.3 : xgBoost Classifier

					Lets train the extereme gradient boosting : xgboost classifier"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	model = xgb.XGBClassifier(n_estimators=300, learning_rate=0.01)
					model.fit(train_df, Y)
					pred = model.predict(test_df)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))

	def _feature_importance(self):
		## add the intro text cell
		text = """	## Step 5: Feature Importance

					Lets look at some of the important features"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))

		## lets look at the data snapshot
		code = """	plt.figure(figsize=(20,16));
					plot_importance(model, );"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


	def _submission(self):
		## add the intro text cell
		text = """	## Step 6 : Create Submission File

					Finally, create the submission file from the extereme graident boosting model"""
		text = text.replace("\t","")
		self.nb['cells'].append(nbformat.v4.new_markdown_cell(text))


		# self.submission_doc[_target] = pred
		code = """	sub = pd.DataFrame()
					sub[_id] = test_id
					sub[_target] = pred
					sub.to_csv("baseline_submission.csv", index=False)
					sub.head(10)"""
		code = code.replace("\t","")		
		self.nb['cells'].append(nbformat.v4.new_code_cell(code))


	def _generate_notebook(self):
		self._prepare_environment()
		self._dataset_preparation()
		self._dataset_preprocessing()
		self._baseline_model()
		self._feature_importance()
		self._submission()
		nbformat.write(self.nb, 'baseline.ipynb')

if __name__ == "__main__":
	config = {  }
	mg = maggle(config)
	mg._generate_notebook()


